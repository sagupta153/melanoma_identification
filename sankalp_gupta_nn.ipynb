{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue> Melanoma Image Classification using CNN </font> - by Sankalp Gupta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Problem statement: </font> To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Instructions: </font>\n",
    "- Importing Skin Cancer Data\n",
    "- To do: Take necessary actions to read the data\n",
    "- Importing all the important libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> Step 0: </font> Connect to the Github repository to access data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is required to clone the data files from github into google colab.\n",
    "#This has to be executed everytime, as google colab runtime does not store data files, once the program session is removed\n",
    "!git clone https://github.com/sagupta153/melanoma_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify the present working directory. This helps in setting the path for the image data files\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the parent folder where the program and data files are stored. \n",
    "parent_path = '/content/melanoma_identification'     #Use this when executing the program on google colab\n",
    "#parent_path = '.'                                   #Use this when executing the program on local PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> Step 1: </font> Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, glob, shutil\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Notes: </font>\n",
    "- This assignment uses a dataset of about 2357 images of skin cancer types.\n",
    "- The dataset contains 9 sub-directories in each train and test subdirectories.\n",
    "- The 9 sub-directories contains the images of 9 skin cancer types respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> Step 2: </font> Connect with the Image Data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path where the image data files will be found\n",
    "data_path  = parent_path + '/melanomas'\n",
    "\n",
    "train_path = data_path + '/Train'\n",
    "test_path  = data_path + '/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is just to ensure that the program does not crash in case the image files folder is not set properly\n",
    "def crete_dir_if_not_existing (f):\n",
    "    if not os.path.exists(f):\n",
    "        print ('Dir ' + f + ' does not exist. Creating one')\n",
    "        os.mkdir(f)\n",
    "    else:\n",
    "        print ('Dir ' + f + ' exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create directories if they do not exist - This is done to prevent the program from crashing\n",
    "crete_dir_if_not_existing(data_path)\n",
    "crete_dir_if_not_existing(train_path)\n",
    "crete_dir_if_not_existing(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise the path class corresponding to the path-string for image data files\n",
    "train_dir = pathlib.Path(train_path)\n",
    "test_dir  = pathlib.Path(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of image files\n",
    "image_count_train = len(list(train_dir.glob('*/*.jpg')))\n",
    "image_count_test  = len(list(test_dir.glob('*/*.jpg')))\n",
    "\n",
    "print(\"Number of Training Images: \", f\"{image_count_train:>4}\")\n",
    "print(\"Number of Test     Images: \", f\"{image_count_test:>4}\")\n",
    "print('-'*32)\n",
    "print(\"Total Number of    Images: \", f\"{(image_count_train + image_count_test):>4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> Step 3: </font> Load images using image_dataset_from_directory utility from keras.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Instructions: </font>\n",
    "- Write your train dataset here\n",
    "- Use 80% of the images for training, and 20% for validation.\n",
    "- Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
    "- Note, make sure your resize your images to the size img_height*img_width, while writting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This keras utility is a convenient way of loading image files\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height, img_width = 180, 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Training Dataset - 80% of the images used for training\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Validation Dataset - 20% of the images used for validation\n",
    "val_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Instructions: </font>\n",
    "- List out all the classes of skin cancer and store them in a list. \n",
    "- You can find the class names in the class_names attribute on these datasets. \n",
    "- These correspond to the directory names in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all the class names in a list\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> Step 4: </font> Visualize one sample image for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Instructions: </font>\n",
    "- Visualize the data\n",
    "- Todo, create a code to visualize one instance of all the nine classes present in the dataset\n",
    "- your code goes here, you can use training or validation data to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the number of classes\n",
    "num_classes = len (class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display one image from each of the classes\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "for i in range(num_classes):\n",
    "    class_ds = train_ds.filter(lambda _, l: tf.math.equal(l[0], i))\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    \n",
    "    for image, label in class_ds.take(1):    \n",
    "        plt.imshow(image[0].numpy().astype('uint8'))\n",
    "        \n",
    "        l = label.numpy()[0]\n",
    "        title_str = str (l+1) + ':' + class_names[l]\n",
    "        plt.title(title_str)\n",
    "        \n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> Step 5: </font> Visualize Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of images in each class\n",
    "counts = []\n",
    "for c in class_names:\n",
    "    class_dir  = pathlib.Path(train_path + '/' + c)\n",
    "    class_count = len(list(class_dir.glob('*.jpg')))\n",
    "    counts.append (class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the counts to % value\n",
    "counts = np.array (counts) * 100 / np.sum (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display % of data from each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar (class_names, counts)\n",
    "plt.xticks (rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> Step 6: </font> Build CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Notes: </font>\n",
    "- The image_batch is a tensor of the shape (32, 180, 180, 3). This is a batch of 32 images of shape 180x180x3 (the last dimension refers to color channels RGB). The label_batch is a tensor of the shape (32,), these are corresponding labels to the 32 images.\n",
    "\n",
    "- Dataset.cache() keeps the images in memory after they're loaded off disk during the first epoch.\n",
    "\n",
    "- Dataset.prefetch() overlaps data preprocessing and model execution while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Instructions: </font>\n",
    "- Create the model\n",
    "- Todo: Create a CNN model, which can accurately detect 9 classes present in the dataset. \n",
    "- Use layers.experimental.preprocessing.Rescaling to normalize pixel values between (0,1). \n",
    "- The RGB channel values are in the [0, 255] range. \n",
    "- This is not ideal for a neural network. Here, it is good to standardize values to be in the [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> Import Keras libraries for CNN Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential, Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.layers import Input, Add,Dropout, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> Define a function to visualize model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results (history, epochs):\n",
    "    epochs_range = range(epochs)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    acc      = history.history['accuracy']\n",
    "    val_acc  = history.history['val_accuracy']\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc,      label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc,  label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    loss     = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss,     label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> Model 1: </font> 4 Conv layers, 2 Maxpool, 1 Dense, 1 Output-Softmax Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Rescaling(1.0/255, input_shape=(180,180,3)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu', input_shape = (180,180,3)))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "epochs = 20\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model results\n",
    "visualize_results (history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> Model 2: </font> Added Batch Normalization after each Conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Rescaling(1.0/255, input_shape=(180,180,3)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu', input_shape = (180,180,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "epochs = 20\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model results\n",
    "visualize_results (history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> Model 3: </font> Add Dropouts - to remove overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Rescaling(1.0/255, input_shape=(180,180,3)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu', input_shape = (180,180,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "epochs = 20\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model results\n",
    "visualize_results (history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> Model 4: </font> Add LC2 regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Rescaling(1.0/255, input_shape=(180,180,3)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu', input_shape = (180,180,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_regularizer=L2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "epochs = 20\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model results\n",
    "visualize_results (history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Instructions: </font>\n",
    "- Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your findings here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Todo, after you have analysed the model fit history for presence of underfit or overfit, choose an appropriate data augumentation strategy. \n",
    "- Your code goes here\n",
    "- Todo, visualize how your augmentation strategy works for one instance of training image.\n",
    "- Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Todo: </font> Write your findings after the model fit, see if there is an evidence of model overfit or underfit. Do you think there is some improvement now as compared to the previous model run?\n",
    "Todo: Find the distribution of classes in the training dataset.\n",
    "Context: Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> Model 5: </font> Using Augmentor to create an enhanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing output folders from previous execution \n",
    "for c in class_names:\n",
    "    f = train_path + '/' + c + '/output' \n",
    "    if os.path.exists(f):\n",
    "        print ('Dir ' + f + ' exists from previous program execution. Removing the same')\n",
    "        for root, dirs, files in os.walk(f, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "    else:\n",
    "        print ('Dir ' + f + ' does not exist from previous program execution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Note: </font> \n",
    "To use Augmentor, the following general procedure is followed:\n",
    "\n",
    "Instantiate a Pipeline object pointing to a directory containing your initial image data set.\n",
    "Define a number of operations to perform on this data set using your Pipeline object.\n",
    "Execute these operations by calling the Pipeline’s sample() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_names:\n",
    "    p = Augmentor.Pipeline(train_path + '/' + i)\n",
    "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Note: </font> \n",
    "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Note: </font> \n",
    "Lets see the distribution of augmented data after adding new images to the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for c in class_names:\n",
    "    class_dir1  = pathlib.Path(train_path + '/' + c)\n",
    "    class_dir2  = pathlib.Path(train_path + '/' + c + '/output')\n",
    "    class_count = len(list(class_dir1.glob('*.jpg'))) + len(list(class_dir2.glob('*.jpg')))\n",
    "    counts.append (class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array (counts) * 100 / np.sum (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display % of data from each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar (class_names, counts)\n",
    "plt.xticks (rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> Instructions: </font>\n",
    "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process.\n",
    "\n",
    "Todo: Train the model on the data created using Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Training Dataset - 80% of the images used for training\n",
    "train_ds_aug = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=123,\n",
    "    validation_split = 0.2,\n",
    "    subset='training',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Validation Dataset - 20% of the images used for validation\n",
    "val_ds_aug = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=123,\n",
    "    validation_split = 0.2,\n",
    "    subset='validation',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Rescaling(1.0/255, input_shape=(180,180,3)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu', input_shape = (180,180,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters =128, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_regularizer=L2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "epochs = 30\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model results\n",
    "visualize_results (history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> Model 6: </font> Increase epochs to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "epochs = 50\n",
    "history = model.fit(train_ds_aug, validation_data=val_ds_aug, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model results\n",
    "visualize_results (history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> Step 6: </font> Evaluate the model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Validation Dataset - 20% of the images used for validation\n",
    "eval_ds = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels      ='inferred',\n",
    "    label_mode  = \"binary\",\n",
    "    class_names = class_names,\n",
    "    color_mode  =  'rgb',\n",
    "    batch_size  = batch_size, # not really applicable as I want to use the whole set?\n",
    "    image_size  = (img_height, img_width),\n",
    "    shuffle     = True,\n",
    "    seed        = 123,\n",
    "    validation_split = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate (test_images, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
